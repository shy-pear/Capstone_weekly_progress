{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e28b867-15d2-46e2-824f-ed0c659524b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cfdd5e-b5e9-466b-b691-a2e1b082948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190bb1ee-aff4-4dea-9328-fc0f21260b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1551e718-68dc-4c92-8af4-ea3e5656ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df4a992-bf0a-4e61-a91e-02698b0ead05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-mini and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"prajjwal1/bert-mini\"  # Optimized small model\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL)\n",
    "\n",
    "# Load Model\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL, num_labels=2)  # Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d508ed7-db43-420b-8c25-698f83b2ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dataset = load_dataset(\"imdb\")  # Sentiment analysis dataset\n",
    "suicide_dataset = load_dataset(\"vibhorag101/suicide_prediction_dataset_phr\")  # Suicide detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fbf31db-b739-4a6d-a5a0-4d6c5aaf9867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string labels to numeric values\n",
    "def map_labels(example):\n",
    "    # SuicideWatch dataset: Convert \"suicide\" → 1, \"non-suicide\" → 0\n",
    "    if example[\"label\"] == \"suicide\":\n",
    "        example[\"label\"] = 1\n",
    "    elif example[\"label\"] == \"non-suicide\":\n",
    "        example[\"label\"] = 0\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3679a41-9924-4e78-b007-2768d957bfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c72b36bf5f844f796eee5e329fd382d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/185574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15abd4fe39774ed6b8ef12ebd6ef7ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suicide_dataset = suicide_dataset.map(map_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b693d6-139d-47ed-abb6-1f6a687c8d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and Rename Labels Efficiently\n",
    "def preprocess_function(batch):\n",
    "    tokenized = tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    tokenized[\"labels\"] = [int(label) for label in batch[\"label\"]]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97972c5-5d74-4f6d-9246-4359325ce663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ee0f9d733647ca9ee274861e29d192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/185574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc050f7b06964e8daf0ee45e10776c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suicide_dataset = suicide_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92403ea2-73b9-4882-96dc-7e1882e980b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9c408867864da59e176a2a0eb2b40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf5041d17e74d119f8925e6aa82cfe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d2da6357f04da6b60114247cb6813e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_dataset = sentiment_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dba67041-cabc-4510-83f5-a3871774e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove text column (no longer needed)\n",
    "suicide_dataset = suicide_dataset.remove_columns([\"text\"])\n",
    "sentiment_dataset = sentiment_dataset.remove_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27f561b0-e346-415e-8fe4-07df86b9ccd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 1, 'input_ids': [101, 2342, 2203, 6114, 4895, 4783, 5400, 6321, 5051, 27469, 2425, 2994, 2113, 2131, 2488, 3984, 2025, 2025, 2113, 2514, 2051, 16873, 5920, 14337, 16592, 2135, 2025, 16592, 2135, 2025, 2191, 2514, 2488, 2215, 2203, 9826, 2699, 2673, 2052, 2191, 2488, 2920, 2542, 2498, 2499, 2215, 3280, 2342, 3280, 2025, 10107, 9015, 2172, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 1}\n"
     ]
    }
   ],
   "source": [
    "print(suicide_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37f0fef8-1b04-42a3-baac-f62e9224a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Dataset Wrapper\n",
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.dataset = hf_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(item[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(item[\"attention_mask\"], dtype=torch.long),\n",
    "            \"labels\": torch.tensor(item[\"labels\"], dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1761bb71-12d4-4d24-8488-ef0df46a7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap datasets\n",
    "train_suicide_dataset = MultiTaskDataset(suicide_dataset[\"train\"].select(range(50000)))\n",
    "test_suicide_dataset = MultiTaskDataset(suicide_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2919e74d-6a27-4478-acba-88872cbb8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment_dataset = MultiTaskDataset(sentiment_dataset[\"train\"])\n",
    "test_sentiment_dataset = MultiTaskDataset(sentiment_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e9f7822-8a7e-4d29-9bd4-8ae1e53c550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create efficient dataloaders\n",
    "BATCH_SIZE = 8  # Increase batch size for efficiency\n",
    "\n",
    "train_suicide_loader = DataLoader(train_suicide_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_suicide_loader = DataLoader(test_suicide_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_sentiment_loader = DataLoader(train_sentiment_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_sentiment_loader = DataLoader(test_sentiment_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "755a0491-3105-4ee7-a205-934fd437b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Device (Supports Mac MPS and CUDA)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ee32b4b-fd9e-4585-ab7c-5346f7f0aafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eaa0ec1-a609-4e15-b399-25ef86d3a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer & Loss Function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)  # Higher learning rate for BERT-Mini\n",
    "loss_fn = nn.CrossEntropyLoss()  # Binary classification loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22faa00d-88c1-4421-a89e-60c432a5efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model optimizations for less memory usage and better training\n",
    "\n",
    "# Less dropout layers\n",
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.Dropout):\n",
    "        module.p = 0.05  # Reduce dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54bb2a0c-a00b-4e19-9bba-6c556d10cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    nn.LayerNorm(256),  # Normalize before classification\n",
    "    nn.Linear(256, 2)   # Keep original classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "752e1c4d-11af-4cbc-bd4f-96dac40200a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 256, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 256)\n",
       "      (token_type_embeddings): Embedding(2, 256)\n",
       "      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.05, inplace=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.half()  # Convert model weights to float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f906dc32-f5e0-4e3a-8730-1238e3cad9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0637a777-1379-41f7-9b0a-6a0fde7c938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00bc12f7-0958-4a75-a68d-be03c299a317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch._dynamo.eval_frame.OptimizedModule'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa2420c2-e9b0-424f-8bde-0e875a2d110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configurations\n",
    "EPOCHS = 3  # More epochs compensate for smaller model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74630bc1-ab07-4312-9ab7-2ecf1e0b2dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 6016, 3893,  ...,    0,    0,    0],\n",
      "        [ 101, 2471, 2095,  ...,    0,    0,    0],\n",
      "        [ 101, 2052, 2066,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2025, 2360,  ...,    0,    0,    0],\n",
      "        [ 101, 2183, 3892,  ...,    0,    0,    0],\n",
      "        [ 101, 2048, 2154,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 1, 0, 0, 1, 0, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_suicide_loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e5d288e-c7db-42b6-8bfa-7a387c56dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure model is fully on the correct device\n",
    "model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.data = param.data.to(device)\n",
    "    if param.grad is not None:\n",
    "        param.grad.data = param.grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2a7e76e-63d5-44d1-b9c8-f7d12ee7b628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training...\n"
     ]
    },
    {
     "ename": "BackendCompilerFailed",
     "evalue": "backend='inductor' raised:\nLoweringException: TypeError: 'NoneType' object is not callable\n  target: aten.var_mean.correction\n  args[0]: TensorBox(StorageBox(\n    Pointwise(\n      'mps',\n      torch.float32,\n      def inner_fn(index):\n          i0, i1, i2 = index\n          tmp0 = ops.load(buf0, i2 + 256 * i1 + 131072 * i0)\n          tmp1 = ops.to_dtype(tmp0, torch.float32, src_dtype=torch.float16)\n          return tmp1\n      ,\n      ranges=[8, 512, 256],\n      origin_node=convert_element_type,\n      origins=OrderedSet([convert_element_type])\n    )\n  ))\n  args[1]: [2]\n  kwargs: {'correction': 0, 'keepdim': True}\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBackendCompilerFailed\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m inputs = {key: val.to(device) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m batch_suicide.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m     14\u001b[39m labels = batch_suicide[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m loss_suicide = loss_fn(outputs.logits, labels)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Sentiment Task\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:574\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m saved_dynamic_layer_stack_depth = (\n\u001b[32m    570\u001b[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001b[32m    571\u001b[39m )\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    576\u001b[39m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[32m    577\u001b[39m     torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[32m    578\u001b[39m         saved_dynamic_layer_stack_depth\n\u001b[32m    579\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1380\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1374\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1375\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1376\u001b[39m             )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1379\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1164\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1162\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1164\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1166\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:547\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    544\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:986\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m    984\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     guarded_code = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m    989\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    995\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m    996\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m    997\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:715\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    713\u001b[39m     stack.enter_context(torch._dynamo.callback_handler.install_callbacks())\n\u001b[32m    714\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_utils_internal.py:95\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] = skip + \u001b[32m1\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     98\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     99\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:750\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    748\u001b[39m CompileContext.get().attempt = attempt\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     out_code = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.RestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:1361\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1358\u001b[39m instructions = cleaned_instructions(code, safe)\n\u001b[32m   1359\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:231\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m exit_stack.enter_context(torch_function_mode_stack_state_mgr)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    233\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:662\u001b[39m, in \u001b[36m_compile.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    661\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    664\u001b[39m     speculation_log.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2868\u001b[39m, in \u001b[36mInstructionTranslator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2867\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2868\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1052\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1053\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:962\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3048\u001b[39m, in \u001b[36mInstructionTranslator.RETURN_VALUE\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3047\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mRETURN_VALUE\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m3048\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3033\u001b[39m, in \u001b[36mInstructionTranslator._return\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3028\u001b[39m _step_logger()(\n\u001b[32m   3029\u001b[39m     logging.INFO,\n\u001b[32m   3030\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtorchdynamo done tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.f_code.co_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst.opname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3031\u001b[39m )\n\u001b[32m   3032\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m triggered compile\u001b[39m\u001b[33m\"\u001b[39m, inst.opname)\n\u001b[32m-> \u001b[39m\u001b[32m3033\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreason\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGraphCompileReason\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreturn_value\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_break\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3039\u001b[39m return_inst = (\n\u001b[32m   3040\u001b[39m     create_instruction(\u001b[33m\"\u001b[39m\u001b[33mRETURN_VALUE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3041\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inst.opname == \u001b[33m\"\u001b[39m\u001b[33mRETURN_VALUE\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m create_instruction(\u001b[33m\"\u001b[39m\u001b[33mRETURN_CONST\u001b[39m\u001b[33m\"\u001b[39m, argval=inst.argval)\n\u001b[32m   3043\u001b[39m )\n\u001b[32m   3044\u001b[39m \u001b[38;5;28mself\u001b[39m.output.add_output_instructions([return_inst])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1136\u001b[39m, in \u001b[36mOutputGraph.compile_subgraph\u001b[39m\u001b[34m(self, tx, partial_convert, reason)\u001b[39m\n\u001b[32m   1133\u001b[39m output = []\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m count_calls(\u001b[38;5;28mself\u001b[39m.graph) != \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2.graph_outputs) != \u001b[32m0\u001b[39m:\n\u001b[32m   1135\u001b[39m     output.extend(\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgraph_output_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_replacements\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     )\n\u001b[32m   1141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2.graph_outputs) != \u001b[32m0\u001b[39m:\n\u001b[32m   1142\u001b[39m         output.append(pass2.create_store(graph_output_var))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1382\u001b[39m, in \u001b[36mOutputGraph.compile_and_call_fx_graph\u001b[39m\u001b[34m(self, tx, rv, root, replaced_outputs)\u001b[39m\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28mself\u001b[39m.tracing_context.fake_mode = backend_fake_mode\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.restore_global_state():\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     compiled_fn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lazy_graph_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LazyGraphModule\n\u001b[32m   1386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_fn, _LazyGraphModule) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1387\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(compiled_fn, \u001b[33m\"\u001b[39m\u001b[33m__self__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), _LazyGraphModule)\n\u001b[32m   1388\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m compiled_fn.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m_lazy_forward\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1392\u001b[39m     \u001b[38;5;66;03m# this is a _LazyGraphModule. This makes it easier for dynamo to\u001b[39;00m\n\u001b[32m   1393\u001b[39m     \u001b[38;5;66;03m# optimize a _LazyGraphModule.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1432\u001b[39m, in \u001b[36mOutputGraph.call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_user_compiler\u001b[39m(\u001b[38;5;28mself\u001b[39m, gm: fx.GraphModule) -> CompiledFn:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   1427\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOutputGraph.call_user_compiler\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1428\u001b[39m         phase_name=\u001b[33m\"\u001b[39m\u001b[33mbackend_compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1429\u001b[39m         log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1430\u001b[39m         dynamo_compile_column_us=\u001b[33m\"\u001b[39m\u001b[33maot_autograd_cumulative_compile_time_us\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1431\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1483\u001b[39m, in \u001b[36mOutputGraph._call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1481\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1482\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1483\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BackendCompilerFailed(\u001b[38;5;28mself\u001b[39m.compiler_fn, e).with_traceback(\n\u001b[32m   1484\u001b[39m         e.__traceback__\n\u001b[32m   1485\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1487\u001b[39m signpost_event(\n\u001b[32m   1488\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1489\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOutputGraph.call_user_compiler\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1495\u001b[39m     },\n\u001b[32m   1496\u001b[39m )\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/output_graph.py:1462\u001b[39m, in \u001b[36mOutputGraph._call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.verify_correctness:\n\u001b[32m   1461\u001b[39m     compiler_fn = WrapperBackend(compiler_fn)\n\u001b[32m-> \u001b[39m\u001b[32m1462\u001b[39m compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1463\u001b[39m _step_logger()(logging.INFO, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1464\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(compiled_fn), \u001b[33m\"\u001b[39m\u001b[33mcompiler_fn did not return callable\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:130\u001b[39m, in \u001b[36mWrapBackendDebug.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     compiled_gm = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/__init__.py:2340\u001b[39m, in \u001b[36m_TorchCompileInductorWrapper.__call__\u001b[39m\u001b[34m(self, model_, inputs_)\u001b[39m\n\u001b[32m   2337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_, inputs_):\n\u001b[32m   2338\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompile_fx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[32m-> \u001b[39m\u001b[32m2340\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1863\u001b[39m, in \u001b[36mcompile_fx\u001b[39m\u001b[34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001b[39m\n\u001b[32m   1856\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m inference_compiler(unlifted_gm, example_inputs_)\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m V.set_fake_mode(fake_mode), torch._guards.tracing(\n\u001b[32m   1859\u001b[39m     tracing_context\n\u001b[32m   1860\u001b[39m ), compiled_autograd._disable(), functorch_config.patch(\n\u001b[32m   1861\u001b[39m     unlift_effect_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1862\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1863\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1865\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1866\u001b[39m \u001b[43m        \u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1868\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1869\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1871\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/backends/common.py:83\u001b[39m, in \u001b[36mAotAutograd.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# NB: NOT cloned!\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging(), patch_config:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m         cg = \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m         counters[\u001b[33m\"\u001b[39m\u001b[33maot_autograd\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m disable(cg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1155\u001b[39m, in \u001b[36maot_module_simplified\u001b[39m\u001b[34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler, cudagraphs)\u001b[39m\n\u001b[32m   1145\u001b[39m     compiled_fn = AOTAutogradCache.load(\n\u001b[32m   1146\u001b[39m         dispatch_and_compile,\n\u001b[32m   1147\u001b[39m         mod,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1152\u001b[39m         remote,\n\u001b[32m   1153\u001b[39m     )\n\u001b[32m   1154\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m     compiled_fn = \u001b[43mdispatch_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, torch._dynamo.utils.GmWrapper):\n\u001b[32m   1158\u001b[39m     \u001b[38;5;66;03m# This function is called by the flatten_graph_inputs wrapper, which boxes\u001b[39;00m\n\u001b[32m   1159\u001b[39m     \u001b[38;5;66;03m# the inputs so that they can be freed before the end of this scope.\u001b[39;00m\n\u001b[32m   1160\u001b[39m     \u001b[38;5;66;03m# For overhead reasons, this is not the default wrapper, see comment:\u001b[39;00m\n\u001b[32m   1161\u001b[39m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/122535/files#r1560096481\u001b[39;00m\n\u001b[32m   1162\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mboxed_forward\u001b[39m(runtime_args: List[Any]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:1131\u001b[39m, in \u001b[36maot_module_simplified.<locals>.dispatch_and_compile\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1129\u001b[39m functional_call = create_functional_call(mod, params_spec, params_len)\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compiled_autograd._disable():\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m     compiled_fn, _ = \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:580\u001b[39m, in \u001b[36mcreate_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_aot_dispatcher_function\u001b[39m(\n\u001b[32m    573\u001b[39m     flat_fn,\n\u001b[32m    574\u001b[39m     fake_flat_args: FakifiedFlatArgs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    577\u001b[39m     shape_env: Optional[ShapeEnv],\n\u001b[32m    578\u001b[39m ) -> Tuple[Callable, ViewAndMutationMeta]:\n\u001b[32m    579\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mcreate_aot_dispatcher_function\u001b[39m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m            \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_env\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:830\u001b[39m, in \u001b[36m_create_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    826\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m aot_dispatch_base\n\u001b[32m    828\u001b[39m compiler_fn = choose_dispatcher(needs_autograd, aot_config)\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m compiled_fn, fw_metadata = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_dup_fake_script_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn, fw_metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:678\u001b[39m, in \u001b[36maot_dispatch_autograd\u001b[39m\u001b[34m(flat_fn, flat_args, aot_config, fw_metadata)\u001b[39m\n\u001b[32m    675\u001b[39m     tracing_context.fw_metadata = inner_meta\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m TracingContext.report_output_strides() \u001b[38;5;28;01mas\u001b[39;00m fwd_output_strides:\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m     compiled_fw_func = \u001b[43maot_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjusted_flat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(compiled_fw_func, \u001b[33m\"\u001b[39m\u001b[33m_boxed_call\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    681\u001b[39m     compiled_fw_func = make_boxed_func(compiled_fw_func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py:489\u001b[39m, in \u001b[36mSerializableAOTDispatchCompiler.__call__\u001b[39m\u001b[34m(self, gm, example_inputs)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    485\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    486\u001b[39m     gm: torch.fx.GraphModule,\n\u001b[32m    487\u001b[39m     example_inputs: Sequence[InputType],\n\u001b[32m    488\u001b[39m ) -> OutputCode:\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1741\u001b[39m, in \u001b[36mcompile_fx.<locals>.fw_compiler_base\u001b[39m\u001b[34m(gm, example_inputs, is_inference)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1739\u001b[39m     model_outputs_node.meta[\u001b[33m\"\u001b[39m\u001b[33muser_visible_output_idxs\u001b[39m\u001b[33m\"\u001b[39m] = []\n\u001b[32m-> \u001b[39m\u001b[32m1741\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_input_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_static_input_idxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1749\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:569\u001b[39m, in \u001b[36mcompile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    562\u001b[39m stack.enter_context(DebugContext())\n\u001b[32m    564\u001b[39m get_chromium_event_logger().add_event_data(\n\u001b[32m    565\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minductor_compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    566\u001b[39m     is_backward=kwargs[\u001b[33m\"\u001b[39m\u001b[33mis_backward\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    567\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_compiler_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compile_fx_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minductor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_dynamo/repro/after_aot.py:102\u001b[39m, in \u001b[36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m config.repro_after \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maot\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     inner_compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.repro_after == \u001b[33m\"\u001b[39m\u001b[33maot\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:685\u001b[39m, in \u001b[36m_compile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **graph_kwargs)\u001b[39m\n\u001b[32m    683\u001b[39m TritonBundler.begin_compile()\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m     mb_compiled_graph = \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgraph_kwargs\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m mb_compiled_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    689\u001b[39m     mb_compiled_graph._time_taken_ns = time.time_ns() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:1129\u001b[39m, in \u001b[36mfx_codegen_and_compile\u001b[39m\u001b[34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001b[39m\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfx_codegen_and_compile\u001b[39m(\n\u001b[32m   1120\u001b[39m     gm: GraphModule,\n\u001b[32m   1121\u001b[39m     example_inputs: Sequence[InputType],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1125\u001b[39m     **graph_kwargs: Unpack[_CompileFxKwargs],\n\u001b[32m   1126\u001b[39m ) -> OutputCode:\n\u001b[32m   1127\u001b[39m     scheme: FxCompile = _InProcessFxCompile()\n\u001b[32m-> \u001b[39m\u001b[32m1129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscheme\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:979\u001b[39m, in \u001b[36m_InProcessFxCompile.codegen_and_compile\u001b[39m\u001b[34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001b[39m\n\u001b[32m    977\u001b[39m metrics_helper = metrics.CachedMetricsHelper()\n\u001b[32m    978\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m V.set_graph_handler(graph):\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m     \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m     output_strides: List[Optional[Tuple[_StrideExprStr, ...]]] = []\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m graph.graph_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    982\u001b[39m         \u001b[38;5;66;03m# We'll put the output strides in the compiled graph so we\u001b[39;00m\n\u001b[32m    983\u001b[39m         \u001b[38;5;66;03m# can later return them to the caller via TracingContext\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/graph.py:855\u001b[39m, in \u001b[36mGraphLowering.run\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any) -> Any:  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m    854\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mGraphLowering.run\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/fx/interpreter.py:167\u001b[39m, in \u001b[36mInterpreter.run\u001b[39m\u001b[34m(self, initial_env, enable_io_processing, *args)\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28mself\u001b[39m.env[node] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.extra_traceback:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/graph.py:1496\u001b[39m, in \u001b[36mGraphLowering.run_node\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1495\u001b[39m     debug(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1496\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# require the same stride order for dense outputs,\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# 1. user-land view() will not throw because inductor\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m# output different strides than eager\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# 2: as_strided ops, we need make sure its input has same size/stride with\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# eager model to align with eager behavior.\u001b[39;00m\n\u001b[32m   1505\u001b[39m as_strided_ops = [\n\u001b[32m   1506\u001b[39m     torch.ops.aten.as_strided.default,\n\u001b[32m   1507\u001b[39m     torch.ops.aten.as_strided_.default,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1510\u001b[39m     torch.ops.aten.resize_as.default,\n\u001b[32m   1511\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/fx/interpreter.py:230\u001b[39m, in \u001b[36mInterpreter.run_node\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/graph.py:1143\u001b[39m, in \u001b[36mGraphLowering.call_function\u001b[39m\u001b[34m(self, target, args, kwargs)\u001b[39m\n\u001b[32m   1141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m   1142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1143\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LoweringException(e, target, args, kwargs).with_traceback(\n\u001b[32m   1144\u001b[39m         e.__traceback__\n\u001b[32m   1145\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/graph.py:1133\u001b[39m, in \u001b[36mGraphLowering.call_function\u001b[39m\u001b[34m(self, target, args, kwargs)\u001b[39m\n\u001b[32m   1130\u001b[39m     old_args, old_kwargs = args, kwargs\n\u001b[32m   1131\u001b[39m     args, kwargs = layout_constraints(n, *args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m out = \u001b[43mlowerings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m layout_constraints:\n\u001b[32m   1136\u001b[39m     \u001b[38;5;66;03m# layout_constraints are allowed to make new copies of the inputs.\u001b[39;00m\n\u001b[32m   1137\u001b[39m     \u001b[38;5;66;03m# if they do, and if the target is mutable, then we need to\u001b[39;00m\n\u001b[32m   1138\u001b[39m     \u001b[38;5;66;03m# write the new values back into the original inputs.\u001b[39;00m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28mself\u001b[39m.propagate_mutation(n, old_args, old_kwargs, args, kwargs)  \u001b[38;5;66;03m# type: ignore[possibly-undefined]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/lowering.py:409\u001b[39m, in \u001b[36m_register_lowering.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m unpacked:\n\u001b[32m    407\u001b[39m     args = [args]\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m out = \u001b[43mdecomp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m validate_ir(out)\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/lowering.py:5482\u001b[39m, in \u001b[36mvar_mean\u001b[39m\u001b[34m(x, axis, correction, keepdim)\u001b[39m\n\u001b[32m   5480\u001b[39m \u001b[38;5;129m@register_lowering\u001b[39m(aten.var_mean)\n\u001b[32m   5481\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvar_mean\u001b[39m(x, axis=\u001b[38;5;28;01mNone\u001b[39;00m, *, correction=\u001b[38;5;28;01mNone\u001b[39;00m, keepdim=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m5482\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvar_mean_helper_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorrection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_mean\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m   5484\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/lowering.py:5467\u001b[39m, in \u001b[36mvar_mean_helper_\u001b[39m\u001b[34m(x, axis, correction, keepdim, return_mean)\u001b[39m\n\u001b[32m   5456\u001b[39m x = to_dtype(x, compute_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   5457\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m   5458\u001b[39m     x=x,\n\u001b[32m   5459\u001b[39m     axis=axis,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5462\u001b[39m     return_mean=return_mean,\n\u001b[32m   5463\u001b[39m )\n\u001b[32m   5464\u001b[39m output = (\n\u001b[32m   5465\u001b[39m     var_mean_sum_(**kwargs)\n\u001b[32m   5466\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_two_step_variance(x, axis=axis, keepdim=keepdim)\n\u001b[32m-> \u001b[39m\u001b[32m5467\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mvar_mean_welford_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5468\u001b[39m )\n\u001b[32m   5469\u001b[39m output = \u001b[38;5;28mtuple\u001b[39m(to_dtype(x, out_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output)\n\u001b[32m   5470\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_mean \u001b[38;5;28;01melse\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/lowering.py:5421\u001b[39m, in \u001b[36mvar_mean_welford_\u001b[39m\u001b[34m(x, axis, correction, keepdim, return_mean)\u001b[39m\n\u001b[32m   5418\u001b[39m kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mdst_dtype\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5419\u001b[39m kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33msrc_dtype\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m5421\u001b[39m mean, m2, _ = \u001b[43mir\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWelfordReduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5422\u001b[39m \u001b[43m    \u001b[49m\u001b[43minner_fns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwelford_reduce\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5425\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5426\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5427\u001b[39m m2.realize()\n\u001b[32m   5429\u001b[39m dtype = x.get_dtype()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/ir.py:1771\u001b[39m, in \u001b[36mWelfordReduction.create\u001b[39m\u001b[34m(cls, device, dtype, inner_fns, ranges, reduction_ranges, reduction_type, reduction_hint)\u001b[39m\n\u001b[32m   1752\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(copy(fn) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m inner_fns)\n\u001b[32m   1754\u001b[39m \u001b[38;5;66;03m# TODO: Unrolled reduction\u001b[39;00m\n\u001b[32m   1755\u001b[39m \u001b[38;5;66;03m# if (\u001b[39;00m\n\u001b[32m   1756\u001b[39m \u001b[38;5;66;03m#     isinstance(reduction_numel, Integer)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1769\u001b[39m \n\u001b[32m   1770\u001b[39m \u001b[38;5;66;03m# triton doesn't support reduce to single element well, so break it up\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1771\u001b[39m hint, split = \u001b[43mReduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_splits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1772\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1773\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1774\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1775\u001b[39m \u001b[43m    \u001b[49m\u001b[43minner_fns\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreduction_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreduction_numel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduction_numel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# intermediate reduction in split can contain complex indexing,\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# and num_splits will fail to correctly set the hint\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# reuse the passed hint if available\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduction_hint == ReductionHint.DEFAULT:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/ir.py:1048\u001b[39m, in \u001b[36mReduction.num_splits\u001b[39m\u001b[34m(device, dst_dtype, src_dtype, inner_fn, ranges, reduction_ranges, reduction_type, reduction_numel, input_node)\u001b[39m\n\u001b[32m   1044\u001b[39m reduction_numel_hint = V.graph.sizevars.symbolic_hint(reduction_numel)\n\u001b[32m   1045\u001b[39m numel_hint = V.graph.sizevars.symbolic_hint(sympy_product(ranges))\n\u001b[32m   1047\u001b[39m should_split = reduction_type == \u001b[33m\"\u001b[39m\u001b[33mscan\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1048\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mV\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBackendFeature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mREDUCE_TO_SINGLE_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m reduction_type\n\u001b[32m   1050\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1051\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33margmax\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1052\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33margmin\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1053\u001b[39m     )\n\u001b[32m   1054\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m config.split_reductions\n\u001b[32m   1055\u001b[39m )\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (_is_static(reduction_numel_hint) \u001b[38;5;129;01mand\u001b[39;00m _is_static(numel_hint)):\n\u001b[32m   1057\u001b[39m     \u001b[38;5;66;03m# We don't support unbacked symints\u001b[39;00m\n\u001b[32m   1058\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ReductionHint.DEFAULT, \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/graph.py:505\u001b[39m, in \u001b[36mGraphLowering.has_feature\u001b[39m\u001b[34m(self, device, feature)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_feature\u001b[39m(\n\u001b[32m    500\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    501\u001b[39m     device: Union[torch._inductor.ir.IRNode, device, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[32m    502\u001b[39m     feature: BackendFeature,\n\u001b[32m    503\u001b[39m ) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    504\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature, BackendFeature), feature\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_backend_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_device_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DetectionBot/virtual_env/lib/python3.12/site-packages/torch/_inductor/codegen/common.py:324\u001b[39m, in \u001b[36mget_backend_features\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    322\u001b[39m     device = torch.device(device_type)\n\u001b[32m    323\u001b[39m scheduling = get_scheduling_for_device(device_type)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscheduling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m.get_backend_features(device)\n",
      "\u001b[31mBackendCompilerFailed\u001b[39m: backend='inductor' raised:\nLoweringException: TypeError: 'NoneType' object is not callable\n  target: aten.var_mean.correction\n  args[0]: TensorBox(StorageBox(\n    Pointwise(\n      'mps',\n      torch.float32,\n      def inner_fn(index):\n          i0, i1, i2 = index\n          tmp0 = ops.load(buf0, i2 + 256 * i1 + 131072 * i0)\n          tmp1 = ops.to_dtype(tmp0, torch.float32, src_dtype=torch.float16)\n          return tmp1\n      ,\n      ranges=[8, 512, 256],\n      origin_node=convert_element_type,\n      origins=OrderedSet([convert_element_type])\n    )\n  ))\n  args[1]: [2]\n  kwargs: {'correction': 0, 'keepdim': True}\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    num_batches = min(len(train_suicide_loader), len(train_sentiment_loader))  # Ensure equal batches\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS} - Training...\")\n",
    "\n",
    "    for batch_idx, (batch_suicide, batch_sentiment) in enumerate(zip(train_suicide_loader, train_sentiment_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Suicide Task\n",
    "        inputs = {key: val.to(device) for key, val in batch_suicide.items() if key in [\"input_ids\", \"attention_mask\"]}\n",
    "        labels = batch_suicide[\"labels\"].to(device)\n",
    "        outputs = model(**inputs)\n",
    "        loss_suicide = loss_fn(outputs.logits, labels)\n",
    "\n",
    "        # Sentiment Task\n",
    "        inputs = {key: val.to(device) for key, val in batch_sentiment.items() if key in [\"input_ids\", \"attention_mask\"]}\n",
    "        labels = batch_sentiment[\"labels\"].to(device)\n",
    "        outputs = model(**inputs)\n",
    "        loss_sentiment = loss_fn(outputs.logits, labels)\n",
    "\n",
    "        # Combine Losses\n",
    "        total_loss = (loss_suicide + loss_sentiment) / 2\n",
    "\n",
    "        # Backpropagation\n",
    "        total_loss.backward()  \n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging Progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Batch {batch_idx}/{num_batches} - Loss: {total_loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1} completed. Avg Loss: {total_loss.item():.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c01352-91cf-4e5a-843f-3261c2af0660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
